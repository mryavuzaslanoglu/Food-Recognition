import tensorflow as tf
import numpy as np
from PIL import Image
import io
from typing import Tuple
import google.generativeai as genai
from app.core.config import settings
import logging

# Logging ayarlarÄ±
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

class ModelService:
    def __init__(self):
        self.interpreter = None
        self.class_names = []
        self._load_model()
        self._load_class_names()
        self._setup_gemini()

    def _load_model(self):
        try:
            self.interpreter = tf.lite.Interpreter(model_path=settings.MODEL_PATH)
            self.interpreter.allocate_tensors()
            self.input_details = self.interpreter.get_input_details()
            self.output_details = self.interpreter.get_output_details()
            self.input_shape = self.input_details[0]['shape']
            logger.debug(f"Input details: {self.input_details}")
            logger.debug(f"Output details: {self.output_details}")
        except Exception as e:
            logger.error(f"Model yÃ¼kleme hatasÄ±: {e}")
            raise

    def _load_class_names(self):
        try:
            with open(settings.CLASS_NAMES_PATH, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.startswith('#') or not line.strip():
                        continue
                    eng, tr = line.strip().split('|')
                    self.class_names.append(tr)
            logger.debug(f"Loaded {len(self.class_names)} class names")
        except Exception as e:
            logger.error(f"SÄ±nÄ±f isimleri yÃ¼kleme hatasÄ±: {e}")
            raise

    def _setup_gemini(self):
        if settings.GEMINI_API_KEY:
            genai.configure(api_key=settings.GEMINI_API_KEY)
            self.model_gemini = genai.GenerativeModel('gemini-1.5-flash')
        else:
            logger.warning("GEMINI_API_KEY bulunamadÄ±")

    def preprocess_image(self, image_data: bytes) -> Tuple[np.ndarray, Image.Image]:
        try:
            # Bytes'Ä± PIL Image'a dÃ¶nÃ¼ÅŸtÃ¼r
            image = Image.open(io.BytesIO(image_data))

            # RGB'ye dÃ¶nÃ¼ÅŸtÃ¼r
            if image.mode != 'RGB':
                image = image.convert('RGB')

            # Model iÃ§in yeniden boyutlandÄ±r
            model_image = image.resize((224, 224))

            # NumPy dizisine dÃ¶nÃ¼ÅŸtÃ¼r
            img_array = np.array(model_image, dtype=np.float32)
            logger.debug(f"Image array shape before processing: {img_array.shape}")

            # Normalizasyon
            img_array = img_array / 255.0

            # Batch boyutu ekle
            img_array = np.expand_dims(img_array, axis=0)
            logger.debug(f"Image array shape after processing: {img_array.shape}")

            return img_array, image

        except Exception as e:
            logger.error(f"GÃ¶rÃ¼ntÃ¼ Ã¶n iÅŸleme hatasÄ±: {e}")
            raise

    def verify_and_get_food_info(self, image: Image.Image, model_prediction: str) -> Tuple[str, str]:
        try:
            # GÃ¶rÃ¼ntÃ¼yÃ¼ byte dizisine Ã§evir
            img_byte_arr = io.BytesIO()
            image.save(img_byte_arr, format='JPEG')
            img_byte_arr = img_byte_arr.getvalue()

            prompt = (
                f"Bu fotoÄŸraftaki yemek gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ analiz et. "
                f"Model bu yemeÄŸin '{model_prediction}' olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yor. "
                f"1. Bu tahmin doÄŸru mu? EÄŸer yanlÄ±ÅŸsa, bu yemeÄŸin ne olduÄŸunu TÃ¼rkÃ§e adÄ±yla yaz. "
                f"2. Bu yemeÄŸin detaylÄ± tarifini ver. "
                f"\nLÃ¼tfen ÅŸu formatta cevap ver:\n"
                f"YEMEK_ADI: [TÃ¼rkÃ§e adÄ±]\n"
                f"TARÄ°F:\n"
                f"ðŸ½ï¸ MALZEMELER:\n"
                f"[Malzemeler listesi]\n\n"
                f"ðŸ‘¨â€ðŸ³ HAZIRLANIÅžI:\n"
                f"[AdÄ±m adÄ±m tarif]\n\n"
                f"ðŸ’¡ PÃœF NOKTALARI:\n"
                f"[Ã–nemli ipuÃ§larÄ±]"
            )

            # Gemini API'ye istek gÃ¶nder ve zaman aÅŸÄ±mÄ±nÄ± 60 saniye olarak ayarla
            response = self.model_gemini.generate_content([prompt, image], safety_settings={
                'HARM_CATEGORY_HARASSMENT': 'BLOCK_ONLY_HIGH',
                'HARM_CATEGORY_HATE_SPEECH': 'BLOCK_ONLY_HIGH',
                'HARM_CATEGORY_SEXUALLY_EXPLICIT': 'BLOCK_ONLY_HIGH',
                'HARM_CATEGORY_DANGEROUS_CONTENT': 'BLOCK_ONLY_HIGH',
            }, stream=False)

            response.resolve()
            response_text = response.text
            # TÃ¼m yanÄ±tÄ± log'a yazdÄ±r
            logger.debug(f"Gemini response: {response_text}")

            yemek_adi = "Tarif BulunamadÄ±"
            tarif = "Tarif BulunamadÄ±"

            lines = response_text.split('\n')
            
            yemek_adi_index = -1
            tarif_index = -1

            for i, line in enumerate(lines):
                if line.startswith("YEMEK_ADI:"):
                    yemek_adi_index = i
                elif line.startswith("TARÄ°F:"):
                    tarif_index = i

            if yemek_adi_index != -1:
                yemek_adi = lines[yemek_adi_index].replace("YEMEK_ADI:", "").strip()

            if tarif_index != -1:
                tarif = "\n".join(lines[tarif_index:]).replace("TARÄ°F:", "", 1).strip()

            # DeÄŸiÅŸkenleri ve tÃ¼rlerini yazdÄ±r
            logger.debug(f"Yemek adÄ±: {yemek_adi}, TÃ¼rÃ¼: {type(yemek_adi)}")
            logger.debug(f"Tarif: {tarif}, TÃ¼rÃ¼: {type(tarif)}")

            return yemek_adi, tarif

        except Exception as e:
            logger.error(f"Gemini API hatasÄ±: {e}")
            return model_prediction, "Tarif alÄ±namadÄ±."

    async def predict(self, image_data: bytes) -> Tuple[str,str, float, str]:
        try:
            # GÃ¶rÃ¼ntÃ¼yÃ¼ Ã¶n iÅŸle
            processed_image, original_image = self.preprocess_image(image_data)

            # Model tahminini yap
            self.interpreter.set_tensor(self.input_details[0]['index'], processed_image)
            self.interpreter.invoke()

            # Model Ã§Ä±ktÄ±sÄ±nÄ± al ve boyutlarÄ±nÄ± kontrol et
            predictions = self.interpreter.get_tensor(self.output_details[0]['index'])
            logger.debug(f"Raw predictions shape: {predictions.shape}")
            logger.debug(f"Raw predictions: {predictions}")

            # BoyutlarÄ± dÃ¼zeltme
            predictions = np.squeeze(predictions)  # Fazla boyutlarÄ± kaldÄ±r
            logger.debug(f"Squeezed predictions shape: {predictions.shape}")

            # En yÃ¼ksek olasÄ±lÄ±klÄ± sÄ±nÄ±fÄ± bul
            predicted_class_index = int(np.argmax(predictions))
            confidence = float(predictions[predicted_class_index])
            logger.debug(f"Predicted class index: {predicted_class_index}")
            logger.debug(f"Confidence: {confidence}")

            # Model tahminini al
            if predicted_class_index >= len(self.class_names):
                logger.error(f"Predicted index {predicted_class_index} out of range for {len(self.class_names)} classes")
                raise ValueError("Invalid prediction index")

            model_prediction = self.class_names[predicted_class_index]
            logger.debug(f"Model prediction: {model_prediction}")

            # Gemini ile doÄŸrula ve bilgi al
            yemek_adi, tarif = self.verify_and_get_food_info(
                original_image,
                model_prediction
            )

            # DeÄŸiÅŸkenleri ve tÃ¼rlerini yazdÄ±r
            logger.debug(f"Yemek adÄ±: {yemek_adi}, TÃ¼rÃ¼: {type(yemek_adi)}")
            logger.debug(f"Tarif: {tarif}, TÃ¼rÃ¼: {type(tarif)}")

            return model_prediction, yemek_adi, confidence, tarif

        except Exception as e:
            logger.error(f"Tahmin hatasÄ±: {e}")
            raise

model_service = ModelService()